{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "mode = \"train\"\n",
    "arch = 'resnet18'\n",
    "batch_siez = 1\n",
    "resume = False\n",
    "epoch = 1\n",
    "epochs = 4\n",
    "lr = 0.0001\n",
    "momentum = 0.9\n",
    "weight_decayh = 5e-4\n",
    "seed = 1\n",
    "save_model = 'save'\n",
    "dataset = 'mnist'\n",
    "num_classes = 10\n",
    "data_path = './Datas'\n",
    "save_path = './checkpoints'\n",
    "workers = 4\n",
    "\n",
    "\n",
    "\n",
    "class MNIST(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img = np.array(frame.iloc[idx, :]).astype(np.uint8).reshape(-1, 28, 28)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.labels is not None:\n",
    "            return (self.labels[i], img)\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "def prepare_dataloaders(args):\n",
    "    data_path = os.path.join(os.getcwd(), 'Datas')\n",
    "\n",
    "    train_csv = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
    "\n",
    "    # Split the train set so there is also a validation set\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(train_csv.iloc[:,1:],\n",
    "                                                                            train_csv.iloc[:,0],\n",
    "                                                                            test_size = 0.1)\n",
    "    train_transform = torchvision.transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.RandomCrop(28),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5], # 1 for grayscale channels\n",
    "                                                    std=[0.5])\n",
    "                           ])\n",
    "\n",
    "    valid_transform = torchvision.transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5], # 1 for grayscale channels\n",
    "                                                    std=[0.5])\n",
    "                           ])\n",
    "\n",
    "    train_dataset = MNIST(images = train_images,\n",
    "                        labels = train_labels,\n",
    "                        transform=train_transform)\n",
    "\n",
    "    valid_dataset = MNIST(images = val_images,\n",
    "                        labels = val_labels,\n",
    "                        transform=valid_transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                num_workers = workers,\n",
    "                                                shuffle=True)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                num_workers = workers)\n",
    "\n",
    "\n",
    "    return train_loader, valid_loader, len(train_dataset), len(valid_dataset)\n",
    "\n",
    "def prepare_test_dataloaders(args):\n",
    "    data_path = os.path.join(os.getcwd(), 'Datas')\n",
    "    test_csv = pd.read_csv(os.path.join(data_path, 'test.csv'))\n",
    "\n",
    "    test_transform = torchvision.transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5], # 1 for grayscale channels\n",
    "                                                    std=[0.5])\n",
    "                           ])\n",
    "\n",
    "    test_dataset = MNIST(images = test_csv,\n",
    "                        labels = None,\n",
    "                        transform=test_transform)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                                batch_size = 1,\n",
    "                                                num_workers = workers)\n",
    "\n",
    "    return test_loader, len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1a7f793158bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-1a7f793158bf>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;34m\"\"\" Settings for training \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;34m\"\"\" Settings for HW \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'seed'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import parser\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import torchvision.models as models\n",
    "\n",
    "import Models.resnet as resnet\n",
    "import Models.efficient as efficient\n",
    "\n",
    "from utils import prepare_dataloaders\n",
    "from tqdm import tqdm\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    \"\"\" Settings for training \"\"\"\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    \"\"\" Settings for HW \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    gpu = torch.cuda.device_count() > 1\n",
    "\n",
    "    \"\"\" Prepare the data loaders \"\"\"\n",
    "    train_loader, valid_loader, train_size, valid_size = prepare_dataloaders(args)\n",
    "\n",
    "    \"\"\" Load the training model \"\"\"\n",
    "    if args.arch == \"efficient-l2\":\n",
    "        model = efficient.efficientL2(num_classes=args.num_classes)\n",
    "    elif args.arch == 'resnet18':\n",
    "        model = resnet.resnet18(num_classes=args.num_classes)\n",
    "    elif args.arch == 'resnet34':\n",
    "        model = resnet.resnet34(num_classes=args.num_classes)\n",
    "    elif args.arch == 'resnet50':\n",
    "        model = resnet.resnet50(num_classes=args.num_classes)\n",
    "    elif args.arch == 'resnet101':\n",
    "        model = resnet.resnet101(num_classes=args.num_classes)\n",
    "    elif args.arch == 'resnet152':\n",
    "        model = resnet.resnet152(num_classes=args.num_classes)\n",
    "\n",
    "    \"\"\" Set specified HW \"\"\"\n",
    "    model = torch.nn.DataParallel(model.to(device))\n",
    "\n",
    "    \"\"\" define loss function. \"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    \"\"\" define optimizer \"\"\"\n",
    "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "\n",
    "    print('[Info] Total parameters {} '.format(count_parameters(model)))\n",
    "\n",
    "    if args.resume or args.mode == \"test\":\n",
    "        print('[Info] Loading checkpoint.')\n",
    "        checkpoint = load_checkpoint(args.save)\n",
    "        arch = checkpoint['arch']\n",
    "        args.epoch = checkpoint['epoch']\n",
    "        state_dict = checkpoint['state_dict']\n",
    "        model.load_state_dict(state_dict)\n",
    "        print('[Info] epoch {} arch {}'.format(args.epoch, arch))\n",
    "\n",
    "    \"\"\" run evaluate \"\"\"\n",
    "    if args.mode == \"evaluate\":\n",
    "        _ = run_epoch(model, 'valid', [args.epoch, args.epoch], criterion, optimizer, valid_loader, valid_size, device)\n",
    "        return\n",
    "\n",
    "    \"\"\" run train \"\"\"\n",
    "    best_acc1 = 0.\n",
    "    for e in range(args.epoch, args.epochs + 1):\n",
    "        adjust_learning_rate(optimizer, e, args)\n",
    "\n",
    "        \"\"\" train for one epoch \"\"\"\n",
    "        _ = run_epoch(model, 'train', [e, args.epochs], criterion, optimizer, train_loader, train_size, device)\n",
    "\n",
    "        \"\"\" evaluate on validation set \"\"\"\n",
    "        with torch.no_grad():\n",
    "            acc1 = run_epoch(model, 'valid', [e, args.epochs], criterion, optimizer, valid_loader, valid_size, device)\n",
    "\n",
    "        # Save checkpoint.\n",
    "        is_best = acc1 > best_acc1\n",
    "        best_acc1 = max(acc1, best_acc1)\n",
    "        save_checkpoint({\n",
    "            'epoch': e,\n",
    "            'arch': args.arch,\n",
    "            'state_dict': model.module.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, args.save_path)\n",
    "        print('[Info] acc1 {} best@acc1 {}'.format(acc1, best_acc1))\n",
    "\n",
    "def run_epoch(model, mode, epoch, criterion, optimizer, data_loader, dataset_size, device):\n",
    "    if mode == 'train':\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    start = time.time()\n",
    "    tq = tqdm(data_loader, desc='  - (' + mode + ')   ', leave=False)\n",
    "    for data, target in tq:\n",
    "        # prepare data\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # forward\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1,5))\n",
    "        losses.update(loss.item(), data.size(0))\n",
    "        top1.update(prec1[0], data.size(0))\n",
    "        top5.update(prec5[0], data.size(0))\n",
    "\n",
    "        if mode == 'train':\n",
    "            # compte gradient and do SGD step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        tq.set_description(' - ({}) [ epoch: {}/{} loss: {:.3f}/{:.3f} ] '.format(mode, epoch[0], epoch[1], losses.val, losses.avg))\n",
    "        #tqdm.write\n",
    "    tqdm.write(' - ({})  [ epoch: {}\\ttop@1: {:.3f}\\ttop@5: {:.3f}\\tloss: {:.3f}\\ttime: {:.3f}]'.format(mode, epoch, top1.avg, top5.avg, losses.avg, (time.time() - start)/60.))\n",
    "    return top1.avg\n",
    "\n",
    "def save_checkpoint(state, is_best, prefix):\n",
    "    filename='checkpoints/{}_checkpoint.chkpt'.format(prefix)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'checkpoints/{}_best.chkpt'.format(prefix))\n",
    "    print(' - [Info] The checkpoint file has been updated.')\n",
    "\n",
    "def load_checkpoint(prefix):\n",
    "    filename='checkpoints/{}_checkpoint.chkpt'.format(prefix)\n",
    "    return torch.load(filename)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\" Computes and stores the average and current value \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    lr = args.lr * (0.1 ** (epoch // 100))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\" Computes the accuracy over the k top predictions for the specified values of k \"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        bsz = target.size(0)\n",
    "        '''\n",
    "            https://pytorch.org/docs/stable/torch.html#torch.topk\n",
    "            torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -> (Tensor, LongTensor)\n",
    "        '''\n",
    "        _, pred = output.topk(maxk, 1, largest=True, sorted=True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / bsz))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
