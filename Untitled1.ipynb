{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "mode = \"train\"\n",
    "arch = 'resnet18'\n",
    "batch_siez = 1\n",
    "resume = False\n",
    "epoch = 1\n",
    "epochs = 4\n",
    "lr = 0.0001\n",
    "momentum = 0.9\n",
    "weight_decayh = 5e-4\n",
    "seed = 1\n",
    "save_model = 'save'\n",
    "dataset = 'mnist'\n",
    "num_classes = 10\n",
    "data_path = './Datas'\n",
    "save_path = './checkpoints'\n",
    "workers = 4\n",
    "\n",
    "\n",
    "\n",
    "class MNIST(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img = np.array(frame.iloc[idx, :]).astype(np.uint8).reshape(-1, 28, 28)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.labels is not None:\n",
    "            return (self.labels[i], img)\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "def prepare_dataloaders(args):\n",
    "    data_path = os.path.join(os.getcwd(), 'Datas')\n",
    "\n",
    "    train_csv = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
    "\n",
    "    # Split the train set so there is also a validation set\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(train_csv.iloc[:,1:],\n",
    "                                                                            train_csv.iloc[:,0],\n",
    "                                                                            test_size = 0.1)\n",
    "    train_transform = torchvision.transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.RandomCrop(28),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5], # 1 for grayscale channels\n",
    "                                                    std=[0.5])\n",
    "                           ])\n",
    "\n",
    "    valid_transform = torchvision.transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5], # 1 for grayscale channels\n",
    "                                                    std=[0.5])\n",
    "                           ])\n",
    "\n",
    "    train_dataset = MNIST(images = train_images,\n",
    "                        labels = train_labels,\n",
    "                        transform=train_transform)\n",
    "\n",
    "    valid_dataset = MNIST(images = val_images,\n",
    "                        labels = val_labels,\n",
    "                        transform=valid_transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                num_workers = workers,\n",
    "                                                shuffle=True)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                num_workers = workers)\n",
    "\n",
    "\n",
    "    return train_loader, valid_loader, len(train_dataset), len(valid_dataset)\n",
    "\n",
    "def prepare_test_dataloaders(args):\n",
    "    data_path = os.path.join(os.getcwd(), 'Datas')\n",
    "    test_csv = pd.read_csv(os.path.join(data_path, 'test.csv'))\n",
    "\n",
    "    test_transform = torchvision.transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5], # 1 for grayscale channels\n",
    "                                                    std=[0.5])\n",
    "                           ])\n",
    "\n",
    "    test_dataset = MNIST(images = test_csv,\n",
    "                        labels = None,\n",
    "                        transform=test_transform)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                                batch_size = 1,\n",
    "                                                num_workers = workers)\n",
    "\n",
    "    return test_loader, len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import parser\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import torchvision.models as models\n",
    "\n",
    "import Models.resnet as resnet\n",
    "import Models.efficient as efficient\n",
    "\n",
    "from utils import prepare_dataloaders\n",
    "from tqdm import tqdm\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def main():\n",
    "\n",
    "    \"\"\" Settings for training \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    \"\"\" Settings for HW \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    gpu = torch.cuda.device_count() > 1\n",
    "\n",
    "    \"\"\" Prepare the data loaders \"\"\"\n",
    "    train_loader, valid_loader, train_size, valid_size = prepare_dataloaders(args)\n",
    "\n",
    "    \"\"\" Load the training model \"\"\"\n",
    "    if arch == \"efficient-l2\":\n",
    "        model = efficient.efficientL2(num_classes=num_classes)\n",
    "    elif arch == 'resnet18':\n",
    "        model = resnet.resnet18(num_classes=num_classes)\n",
    "    elif arch == 'resnet34':\n",
    "        model = resnet.resnet34(num_classes=num_classes)\n",
    "    elif arch == 'resnet50':\n",
    "        model = resnet.resnet50(num_classes=num_classes)\n",
    "    elif arch == 'resnet101':\n",
    "        model = resnet.resnet101(num_classes=num_classes)\n",
    "    elif arch == 'resnet152':\n",
    "        model = resnet.resnet152(num_classes=num_classes)\n",
    "\n",
    "    \"\"\" Set specified HW \"\"\"\n",
    "    model = torch.nn.DataParallel(model.to(device))\n",
    "\n",
    "    \"\"\" define loss function. \"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    \"\"\" define optimizer \"\"\"\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "\n",
    "    print('[Info] Total parameters {} '.format(count_parameters(model)))\n",
    "\n",
    "    if resume or mode == \"test\":\n",
    "        print('[Info] Loading checkpoint.')\n",
    "        checkpoint = load_checkpoint(save)\n",
    "        arch = checkpoint['arch']\n",
    "        epoch = checkpoint['epoch']\n",
    "        state_dict = checkpoint['state_dict']\n",
    "        model.load_state_dict(state_dict)\n",
    "        print('[Info] epoch {} arch {}'.format(epoch, arch))\n",
    "\n",
    "    \"\"\" run evaluate \"\"\"\n",
    "    if mode == \"evaluate\":\n",
    "        _ = run_epoch(model, 'valid', [epoch, epoch], criterion, optimizer, valid_loader, valid_size, device)\n",
    "        return\n",
    "\n",
    "    \"\"\" run train \"\"\"\n",
    "    best_acc1 = 0.\n",
    "    for e in range(epoch, epochs + 1):\n",
    "        adjust_learning_rate(optimizer, e, args)\n",
    "\n",
    "        \"\"\" train for one epoch \"\"\"\n",
    "        _ = run_epoch(model, 'train', [e, epochs], criterion, optimizer, train_loader, train_size, device)\n",
    "\n",
    "        \"\"\" evaluate on validation set \"\"\"\n",
    "        with torch.no_grad():\n",
    "            acc1 = run_epoch(model, 'valid', [e, epochs], criterion, optimizer, valid_loader, valid_size, device)\n",
    "\n",
    "        # Save checkpoint.\n",
    "        is_best = acc1 > best_acc1\n",
    "        best_acc1 = max(acc1, best_acc1)\n",
    "        save_checkpoint({\n",
    "            'epoch': e,\n",
    "            'arch': arch,\n",
    "            'state_dict': model.module.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, save_path)\n",
    "        print('[Info] acc1 {} best@acc1 {}'.format(acc1, best_acc1))\n",
    "\n",
    "def run_epoch(model, mode, epoch, criterion, optimizer, data_loader, dataset_size, device):\n",
    "    if mode == 'train':\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    start = time.time()\n",
    "    tq = tqdm(data_loader, desc='  - (' + mode + ')   ', leave=False)\n",
    "    for data, target in tq:\n",
    "        # prepare data\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # forward\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1,5))\n",
    "        losses.update(loss.item(), data.size(0))\n",
    "        top1.update(prec1[0], data.size(0))\n",
    "        top5.update(prec5[0], data.size(0))\n",
    "\n",
    "        if mode == 'train':\n",
    "            # compte gradient and do SGD step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        tq.set_description(' - ({}) [ epoch: {}/{} loss: {:.3f}/{:.3f} ] '.format(mode, epoch[0], epoch[1], losses.val, losses.avg))\n",
    "        #tqdm.write\n",
    "    tqdm.write(' - ({})  [ epoch: {}\\ttop@1: {:.3f}\\ttop@5: {:.3f}\\tloss: {:.3f}\\ttime: {:.3f}]'.format(mode, epoch, top1.avg, top5.avg, losses.avg, (time.time() - start)/60.))\n",
    "    return top1.avg\n",
    "\n",
    "def save_checkpoint(state, is_best, prefix):\n",
    "    filename='checkpoints/{}_checkpoint.chkpt'.format(prefix)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'checkpoints/{}_best.chkpt'.format(prefix))\n",
    "    print(' - [Info] The checkpoint file has been updated.')\n",
    "\n",
    "def load_checkpoint(prefix):\n",
    "    filename='checkpoints/{}_checkpoint.chkpt'.format(prefix)\n",
    "    return torch.load(filename)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\" Computes and stores the average and current value \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    lr = lr * (0.1 ** (epoch // 100))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\" Computes the accuracy over the k top predictions for the specified values of k \"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        bsz = target.size(0)\n",
    "        '''\n",
    "            https://pytorch.org/docs/stable/torch.html#torch.topk\n",
    "            torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -> (Tensor, LongTensor)\n",
    "        '''\n",
    "        _, pred = output.topk(maxk, 1, largest=True, sorted=True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / bsz))\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-5776b2d1db3a>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;34m\"\"\" Prepare the data loaders \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_dataloaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;34m\"\"\" Load the training model \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\github\\Digit-Recognizer-pytorch\\utils.py\u001b[0m in \u001b[0;36mprepare_dataloaders\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     train_loader = torch.utils.data.DataLoader(train_dataset,\n\u001b[1;32m---> 64\u001b[1;33m                                                 \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m                                                 \u001b[0mnum_workers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                                                 shuffle=True)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'batch_size'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
