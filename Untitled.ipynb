{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'Datas')\n",
    "train_data = os.path.join(data_path, 'train.csv')\n",
    "data = pd.read_csv(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "idx = np.random.randint(len(data))\n",
    "img = data.iloc[idx, 1:].astype(np.uint8).values.reshape(28, 28)\n",
    "label = data.iloc[idx, 0]\n",
    "\n",
    "plt.imshow(255 - img, cmap='gray')\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class MNIST(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img = np.array(frame.iloc[idx, :]).astype(np.uint8).reshape(-1, 28, 28)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.labels is not None:\n",
    "            return (self.labels[i], img)\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "def prepare_dataloaders(args):\n",
    "    data_path = os.path.join(os.getcwd(), 'Datas')\n",
    "\n",
    "    train_csv = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
    "\n",
    "    # Split the train set so there is also a validation set\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(train_csv.iloc[:,1:],\n",
    "                                                                            train_csv.iloc[:,0],\n",
    "                                                                            test_size = 0.1)\n",
    "    train_transform = torchvision.transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.RandomCrop(28),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5], # 1 for grayscale channels\n",
    "                                                    std=[0.5])\n",
    "                           ])\n",
    "\n",
    "    valid_transform = torchvision.transforms.Compose([\n",
    "                                transforms.ToPILImage(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5], # 1 for grayscale channels\n",
    "                                                    std=[0.5])\n",
    "                           ])\n",
    "\n",
    "    train_dataset = MNIST(images = train_images,\n",
    "                        labels = train_labels,\n",
    "                        transform=train_transform)\n",
    "\n",
    "    valid_dataset = MNIST(images = val_images,\n",
    "                        labels = val_labels,\n",
    "                        transform=valid_transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                batch_size = args.batch_size,\n",
    "                                                num_workers = args.workers,\n",
    "                                                shuffle=True)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                                batch_size = args.batch_size,\n",
    "                                                num_workers = args.workers)\n",
    "\n",
    "\n",
    "    return train_loader, valid_loader, len(train_dataset), len(valid_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-09893ef7f842>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_dataloaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, train_size, valid_size = prepare_dataloaders(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--mode MODE] [--arch ARCH] [--batch_size B] [--resume R] [--epoch EPOCH]\n",
      "                             [--epochs E] [--lr LR] [--momentum LR] [--weight_decay LR] [--seed S] [--save_model]\n",
      "                             [--dataset DATASET] [--num_classes NUM_CLASSES] [--data_path DATA_PATH]\n",
      "                             [--save_path SAVE_PATH] [--workers W]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\asdf2\\AppData\\Roaming\\jupyter\\runtime\\kernel-a44ac29a-3761-4c0e-941c-f94b21ea80f0.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asdf2\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import parser\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import torchvision.models as models\n",
    "\n",
    "import Models.resnet as resnet\n",
    "import Models.efficient as efficient\n",
    "\n",
    "from utils import prepare_dataloaders\n",
    "from tqdm import tqdm\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Implement Digit recognizer on MNIST datset using pytorch')\n",
    "parser.add_argument('--mode', type=str, default='train',\n",
    "                        help='train/evelaute/test')\n",
    "parser.add_argument('--arch', type=str, default='efficient-l2',\n",
    "                    help='classification model (defulat: efficient)')\n",
    "parser.add_argument('--batch_size', type=int, default=128, metavar='B',\n",
    "                    help='input batch size for training (defulat: 128)')\n",
    "parser.add_argument('--resume', type=bool, default=False, metavar='R',\n",
    "                    help='resume the model from epoch to epochs (defulat: 1)')\n",
    "parser.add_argument('--epoch', type=int, default=1,\n",
    "                    help='number of start epoch to train (defulat: 1)')\n",
    "parser.add_argument('--epochs', type=int, default=512, metavar='E',\n",
    "                    help='number of epochs to train (defulat: 512)')\n",
    "parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
    "                    help='learning rate (defulat: 0.001)')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, metavar='LR',\n",
    "                    help='momentum (defulat: 0.9)')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4, metavar='LR',\n",
    "                    help='weight decay (defulat: 5e-4)')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--save_model', action='store_true', default=False,\n",
    "                    help='For Saving the current Model')\n",
    "parser.add_argument('--dataset', type=str, default='mnist',\n",
    "                    help='training dataset.  (mnist)')\n",
    "parser.add_argument('--num_classes', type=int, default='10',\n",
    "                    help='number of class for training dataset.  (mnist)')\n",
    "parser.add_argument('--data_path', type=str, default='./Datas',\n",
    "                    help='Path of datasets (default: ./Datas)')\n",
    "parser.add_argument('--save_path', type=str, default='./checkpoints',\n",
    "                    help='Path of datasets (default: ./checkpoints)')\n",
    "parser.add_argument('--workers', type=int, default=4, metavar='W',\n",
    "                    help='number of workers (default: 4)')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "if not os.path.isdir(args.save_path):\n",
    "    os.mkdir(args.save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
